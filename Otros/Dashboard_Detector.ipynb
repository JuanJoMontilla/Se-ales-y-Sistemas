{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhPS4/p6M14bwYhIsTPQ3F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanJoMontilla/Senales-y-Sistemas/blob/main/Otros/Dashboard_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Descargar la base de datos\n",
        "!gdown --id \"1nkTCdDU7PzDVyDKWhoJ7cNN7rhdbjMw9\"\n",
        "!wget https://docs.google.com/spreadsheets/d/1nkTCdDU7PzDVyDKWhoJ7cNN7rhdbjMw9/edit?usp=sharing&ouid=118341214742540591942&rtpof=true&sd=true"
      ],
      "metadata": {
        "id": "Nf_B0DkeduEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Canción de prueba\n",
        "!gdown --id \"1I_THlsDbidYfHm3H2UmunHDBENT615me\"\n",
        "!wget https://drive.google.com/file/d/1I_THlsDbidYfHm3H2UmunHDBENT615me"
      ],
      "metadata": {
        "id": "luFxnU1bdwcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x canciones.rar"
      ],
      "metadata": {
        "id": "1az08MBXd0jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp\n",
        "!apt-get install ffmpeg"
      ],
      "metadata": {
        "id": "-mjxsFRae13r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import random\n",
        "import subprocess\n",
        "\n",
        "# Parámetros\n",
        "segment_size = 5 * 48000  # 5 segundos de audio\n",
        "segments_per_song = 4  # 4 segmentos por canción\n",
        "genres = ['Clasica', 'Pop', 'Metal']  # Géneros musicales\n",
        "sample_rate = 48000  # Asegurar que todas las canciones estén a esta frecuencia\n",
        "\n",
        "# Descargar audio desde YouTube y convertir a formato adecuado\n",
        "def download_audio_from_youtube(url, output_file='downloaded_song.wav'):\n",
        "    try:\n",
        "        # Descargar usando yt-dlp\n",
        "        command = [\n",
        "            'yt-dlp', '-x', '--audio-format', 'wav',\n",
        "            '--output', 'temp_audio.%(ext)s', url\n",
        "        ]\n",
        "        subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "        # Convertir audio a WAV, mono, frecuencia de muestreo de 48kHz\n",
        "        command = [\n",
        "            'ffmpeg', '-i', 'temp_audio.wav', '-ar', str(sample_rate), '-ac', '1',  # '1' es para audio mono\n",
        "            output_file, '-y'\n",
        "        ]\n",
        "        subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "        # Limpiar archivo temporal\n",
        "        os.remove('temp_audio.wav')\n",
        "        return output_file\n",
        "    except Exception as e:\n",
        "        print(f\"Error descargando o procesando el audio de YouTube: {e}\")\n",
        "        return None\n",
        "\n",
        "# Asegurar que el audio sea mono y tenga la longitud adecuada\n",
        "def verify_audio_shape(song):\n",
        "    if len(song.shape) > 1:  # Si es estéreo\n",
        "        song = song.mean(axis=1)  # Convertir a mono\n",
        "    return song\n",
        "\n",
        "# Calcular el espectro de Fourier de los segmentos de una canción\n",
        "def calculate_song_spectra(song, song_length):\n",
        "    song_segments = []\n",
        "    for _ in range(segments_per_song):\n",
        "        segment_start = random.randint(0, song_length - segment_size)\n",
        "        segment_end = segment_start + segment_size\n",
        "        if segment_end > song_length:\n",
        "            segment = np.zeros(segment_size)\n",
        "            segment[:song_length - segment_start] = song[segment_start:]\n",
        "        else:\n",
        "            segment = song[segment_start:segment_end]\n",
        "        spectrum = np.abs(np.fft.fft(segment))\n",
        "        song_segments.append(spectrum)\n",
        "    return song_segments\n",
        "\n",
        "# Clasificación de la canción en uno de los géneros\n",
        "def classify_song(song_path):\n",
        "    try:\n",
        "        # Leer la canción y asegurarse que tenga la frecuencia de muestreo correcta\n",
        "        song, actual_sample_rate = sf.read(song_path)\n",
        "\n",
        "        if actual_sample_rate != sample_rate:\n",
        "            print(f\"La frecuencia de muestreo del archivo es {actual_sample_rate}, debería ser {sample_rate}.\")\n",
        "            return None\n",
        "\n",
        "        # Convertir la canción a mono si es estéreo\n",
        "        song = verify_audio_shape(song)\n",
        "\n",
        "        song_length = len(song)\n",
        "        song_spectra = calculate_song_spectra(song, song_length)\n",
        "\n",
        "        # Comparar el espectro de Fourier con la base de datos de géneros\n",
        "        distances = {}\n",
        "        for genre in genres:\n",
        "            distances[genre] = np.mean([np.linalg.norm(spectrum - spectra_db[genre]) for spectrum in song_spectra])\n",
        "\n",
        "        return min(distances, key=distances.get)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al clasificar la canción: {e}\")\n",
        "        return None\n",
        "\n",
        "# Base de datos de espectros de Fourier por género\n",
        "song_spectra = {}\n",
        "for genre in genres:\n",
        "    song_spectra[genre] = []\n",
        "    genre_dir = os.path.join('canciones', genre)\n",
        "    for song_path in os.listdir(genre_dir):\n",
        "        song, _ = sf.read(os.path.join(genre_dir, song_path))\n",
        "        song = verify_audio_shape(song)  # Asegurar que todas las canciones sean mono\n",
        "        song_length = len(song)\n",
        "        song_spectra[genre].extend(calculate_song_spectra(song, song_length))\n",
        "\n",
        "spectra_db = {}\n",
        "for genre in genres:\n",
        "    spectra_db[genre] = np.mean(song_spectra[genre], axis=0)\n",
        "\n",
        "\n",
        "# Graficar la separabilidad de los géneros y la canción clasificada\n",
        "def plot_genre_separability(song_spectra, spectra_db, song_spectra_classified, genres):\n",
        "    # Preparar datos para PCA\n",
        "    X = []\n",
        "    y = []\n",
        "    genre_labels = []\n",
        "    for genre in genres:\n",
        "        # Tomar los espectros de cada género\n",
        "        X.extend(song_spectra[genre])\n",
        "        genre_labels.extend([genre] * len(song_spectra[genre]))\n",
        "\n",
        "    # Normalizar los datos\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Aplicar PCA para reducir a 2D\n",
        "    pca = PCA(n_components=2)\n",
        "    X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "    # Graficar los puntos de los géneros\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = sns.color_palette(\"viridis\", len(genres))  # Colores con viridis como en tu imagen\n",
        "\n",
        "    for i, genre in enumerate(genres):\n",
        "        genre_data = X_pca[np.array(genre_labels) == genre]\n",
        "        plt.scatter(genre_data[:, 0], genre_data[:, 1], label=genre, c=[colors[i]] * len(genre_data))\n",
        "\n",
        "    # Calcular el PCA para la canción clasificada\n",
        "    song_scaled = scaler.transform(song_spectra_classified.reshape(1, -1))\n",
        "    song_pca = pca.transform(song_scaled)\n",
        "\n",
        "    # Graficar el punto de la canción clasificada\n",
        "    plt.scatter(song_pca[0, 0], song_pca[0, 1], color='red', marker='x', s=200, label='Canción analizada')\n",
        "\n",
        "    # Añadir leyenda y etiquetas\n",
        "    plt.title(\"Separabilidad de géneros y clasificación de la canción\")\n",
        "    plt.xlabel(\"PCA Componente 1\")\n",
        "    plt.ylabel(\"PCA Componente 2\")\n",
        "    plt.legend()\n",
        "    plt.colorbar(plt.cm.ScalarMappable(cmap=\"viridis\"), label=\"Escala de colores\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def play_song_segment(song_path, segment_duration=5):\n",
        "    try:\n",
        "        song, sample_rate = sf.read(song_path)\n",
        "        # Elegir un segmento aleatorio de la canción de duración definida\n",
        "        segment_start = random.randint(0, len(song) - segment_duration * sample_rate)\n",
        "        segment_end = segment_start + segment_duration * sample_rate\n",
        "        song_segment = song[segment_start:segment_end]\n",
        "\n",
        "        # Asegurarse que sea mono para la reproducción (si tiene más de un canal)\n",
        "        if len(song_segment.shape) > 1:\n",
        "            song_segment = song_segment.mean(axis=1)\n",
        "\n",
        "        # Reproducir el segmento de audio\n",
        "        return Audio(song_segment, rate=sample_rate)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al reproducir el segmento de la canción: {e}\")\n",
        "        return None\n",
        "\n",
        "def classify_song_from_youtube(youtube_url):\n",
        "    downloaded_song_path = download_audio_from_youtube(youtube_url)\n",
        "    if downloaded_song_path:\n",
        "        genre = classify_song(downloaded_song_path)\n",
        "        if genre:\n",
        "            print(f\"La canción se clasifica como: {genre}\")\n",
        "            # Graficar la separabilidad\n",
        "            song_spectra_classified = np.mean(calculate_song_spectra(sf.read(downloaded_song_path)[0], len(sf.read(downloaded_song_path)[0])), axis=0)\n",
        "            plot_genre_separability(song_spectra, spectra_db, song_spectra_classified, genres)\n",
        "            # Reproducir un segmento de la canción\n",
        "            print(\"Reproduciendo un segmento de la canción analizada:\")\n",
        "            return play_song_segment(downloaded_song_path)\n",
        "        else:\n",
        "            print(\"No se pudo clasificar la canción.\")\n",
        "    else:\n",
        "        print(\"No se pudo devolver la clasificación.\")"
      ],
      "metadata": {
        "id": "_jUBApOve2bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from IPython.display import Audio\n",
        "import soundfile as sf\n",
        "\n",
        "# Ejecutar la clasificación y mostrar el gráfico\n",
        "youtube_url = \"https://www.youtube.com/watch?v=Qz9gmiLBVFA\"  # Reemplazar con el enlace correcto\n",
        "classify_song_from_youtube(youtube_url)"
      ],
      "metadata": {
        "id": "w-hG_6ZLfMhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Parámetros\n",
        "segment_size = 5 * 48000  # 5 segundos de audio\n",
        "segments_per_song = 4  # 4 segmentos por canción\n",
        "genres = ['Clasica', 'Pop', 'Metal']  # Géneros musicales\n",
        "sample_rate = 48000\n",
        "\n",
        "# Función para extraer segmentos de espectros de Fourier de las canciones\n",
        "def calculate_song_spectra(song, song_length):\n",
        "    song_segments = []\n",
        "    for _ in range(segments_per_song):\n",
        "        segment_start = np.random.randint(0, song_length - segment_size)\n",
        "        segment_end = segment_start + segment_size\n",
        "        if segment_end > song_length:\n",
        "            segment = np.zeros(segment_size)\n",
        "            segment[:song_length - segment_start] = song[segment_start:]\n",
        "        else:\n",
        "            segment = song[segment_start:segment_end]\n",
        "        spectrum = np.abs(np.fft.fft(segment))\n",
        "        song_segments.append(spectrum[:segment_size // 2])  # Usamos solo la mitad del espectro (frecuencias positivas)\n",
        "    return song_segments\n",
        "\n",
        "# Recolectar datos para entrenar\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for genre in genres:\n",
        "    genre_dir = os.path.join('canciones', genre)\n",
        "    for song_path in os.listdir(genre_dir):\n",
        "        song, _ = sf.read(os.path.join(genre_dir, song_path))\n",
        "        song_length = len(song)\n",
        "        if song_length >= segment_size:\n",
        "            spectra = calculate_song_spectra(song, song_length)\n",
        "            X.extend(spectra)\n",
        "            y.extend([genre] * len(spectra))\n",
        "\n",
        "# Convertir a formato numpy y aplanar cada espectro\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Aplanar los datos de 3D a 2D\n",
        "X = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluar el modelo\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Precisión del modelo: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Guardar el modelo\n",
        "joblib.dump(model, 'genre_classifier_model.pkl')\n",
        "print(\"Modelo guardado como 'genre_classifier_model.pkl'\")"
      ],
      "metadata": {
        "id": "nt6iX2CxfNdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install yt-dlp\n",
        "!pip install soundfile\n",
        "!pip install joblib\n",
        "!apt-get install ffmpeg"
      ],
      "metadata": {
        "id": "bcDmTX-kfTsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import joblib\n",
        "from yt_dlp import YoutubeDL\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "from IPython.display import Audio\n",
        "\n",
        "# Parámetros\n",
        "segment_size = 5 * 48000  # 5 segundos de audio, lo que resulta en 240,000 características en la FFT\n",
        "sample_rate = 48000  # Frecuencia de muestreo esperada\n",
        "expected_features = 240000  # El número de características que espera el modelo\n",
        "genres = ['Clasica', 'Pop', 'Metal']  # Definir los géneros musicales\n",
        "\n",
        "# Cargar el modelo preentrenado\n",
        "model = joblib.load('genre_classifier_model.pkl')\n",
        "\n",
        "# Función para descargar y convertir el audio de YouTube\n",
        "def download_audio_from_youtube(url, output_file='downloaded_song.wav'):\n",
        "    try:\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'wav',\n",
        "                'preferredquality': '192',\n",
        "            }],\n",
        "            'outtmpl': 'temp_audio.%(ext)s',\n",
        "        }\n",
        "        with YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "\n",
        "        # Convertir el archivo a mono y frecuencia de muestreo 48kHz\n",
        "        command = [\n",
        "            'ffmpeg', '-i', 'temp_audio.wav', '-ar', str(sample_rate), '-ac', '1',\n",
        "            output_file, '-y'\n",
        "        ]\n",
        "        subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "        os.remove('temp_audio.wav')  # Eliminar el archivo temporal\n",
        "        return output_file\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al descargar o procesar el audio de YouTube: {e}\")\n",
        "        return None\n",
        "\n",
        "# Función para verificar que el audio sea mono y tenga la longitud adecuada\n",
        "def verify_audio_shape(song):\n",
        "    if len(song.shape) > 1:  # Si es estéreo\n",
        "        song = song.mean(axis=1)  # Convertir a mono\n",
        "    return song\n",
        "\n",
        "# Función para extraer el espectro de Fourier de una canción cargada\n",
        "def calculate_song_spectra(song, song_length):\n",
        "    song_segments = []\n",
        "    for _ in range(4):  # Dividimos la canción en 4 segmentos de 5 segundos\n",
        "        segment_start = np.random.randint(0, song_length - segment_size)\n",
        "        segment_end = segment_start + segment_size\n",
        "        if segment_end > song_length:\n",
        "            segment = np.zeros(segment_size)\n",
        "            segment[:song_length - segment_start] = song[segment_start:]\n",
        "        else:\n",
        "            segment = song[segment_start:segment_end]\n",
        "        spectrum = np.abs(np.fft.fft(segment))\n",
        "        song_segments.append(spectrum[:segment_size])  # Usar todo el espectro\n",
        "    return np.mean(song_segments, axis=0)\n",
        "\n",
        "# Graficar la separabilidad de los géneros y la canción clasificada\n",
        "def plot_genre_separability(X_train_pca, y_train, song_pca, genres):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = sns.color_palette(\"viridis\", len(genres))  # Colores con viridis\n",
        "\n",
        "    for i, genre in enumerate(genres):\n",
        "        plt.scatter(X_train_pca[y_train == genre, 0], X_train_pca[y_train == genre, 1],\n",
        "                    color=colors[i], label=genre, alpha=0.7)\n",
        "\n",
        "    plt.scatter(song_pca[0, 0], song_pca[0, 1], color='red', marker='x', s=200, label='Canción analizada')\n",
        "    plt.title(\"Separabilidad de géneros y clasificación de la canción\")\n",
        "    plt.xlabel(\"PCA Componente 1\")\n",
        "    plt.ylabel(\"PCA Componente 2\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    st.pyplot(plt)\n",
        "\n",
        "# Interfaz de Streamlit\n",
        "st.title(\"Detector de Género Musical desde YouTube\")\n",
        "\n",
        "# Pedir enlace de YouTube\n",
        "youtube_url = st.text_input(\"Ingresa el enlace de YouTube de la canción\")\n",
        "\n",
        "if youtube_url:\n",
        "    # Descargar y convertir la canción de YouTube\n",
        "    with st.spinner(\"Descargando y procesando la canción...\"):\n",
        "        downloaded_song_path = download_audio_from_youtube(youtube_url)\n",
        "\n",
        "    if downloaded_song_path:\n",
        "        # Leer la canción descargada\n",
        "        song, sample_rate = sf.read(downloaded_song_path)\n",
        "\n",
        "        # Verificar que la longitud del audio sea suficiente\n",
        "        if len(song) >= segment_size:\n",
        "            # Asegurar que la canción sea mono\n",
        "            song = verify_audio_shape(song)\n",
        "\n",
        "            # Calcular los espectros de Fourier\n",
        "            spectra = calculate_song_spectra(song, len(song))\n",
        "\n",
        "            # Verificar el tamaño del espectro (debe ser igual al esperado)\n",
        "            if len(spectra) != expected_features:\n",
        "                st.error(f\"El espectro calculado tiene {len(spectra)} características, pero se esperaban {expected_features}.\")\n",
        "            else:\n",
        "                # Realizar la predicción con el modelo cargado\n",
        "                genre_prediction = model.predict([spectra])\n",
        "\n",
        "                # Mostrar el resultado\n",
        "                st.write(f\"Género Predicho: *{genre_prediction[0]}*\")\n",
        "\n",
        "                # Reproducir 20 segundos de la canción\n",
        "                segment_start = np.random.randint(0, len(song) - (20 * sample_rate))\n",
        "                segment = song[segment_start:segment_start + (20 * sample_rate)]\n",
        "                sf.write('segment.wav', segment, sample_rate)\n",
        "                st.audio('segment.wav', format='audio/wav')\n",
        "        else:\n",
        "            st.error(\"El archivo de audio esperado es:\")"
      ],
      "metadata": {
        "id": "fGVJkS4HfjcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Token personal de ngrok\n",
        "token = \"2lLFMBWiinIoZUi3bX7RF26eFeD_5KBTy8DqrMYoE2mf5Sqnc\"  # Reemplaza con tu token\n",
        "ngrok.set_auth_token(token)\n",
        "\n",
        "# Ejecutar Streamlit en el puerto 5011\n",
        "!nohup streamlit run app.py --server.port 5011 &\n",
        "\n",
        "# Iniciar el túnel Ngrok y exponer Streamlit en una URL.\n",
        "public_url = ngrok.connect(5011)\n",
        "print(f\"Aplicación aquí: {public_url}\")"
      ],
      "metadata": {
        "id": "JPGlEdllfmpW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}